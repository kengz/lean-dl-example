workflows:
  # https://docs.dstack.ai/usage/conda/
  - name: conda-setup-train
    help: Directly setup Conda env and train, all-in-one
    provider: bash
    commands:
      - conda env create --file environment.yml
      - conda activate dl
      - python dl/train.py
    artifacts:
      - path: lightning_logs

  # below splits the above into distinct workflows to run more efficiently by reusing Conda env
  - name: conda-setup
    help: Setup Conda env as artifact for reuse by mounting
    provider: bash
    commands:
      - conda env create --file environment.yml
    artifacts:
      - path: /opt/conda/envs/dl

  - name: conda-download
    help: Download the dataset
    provider: bash
    deps:
      - workflow: conda-setup
    commands:
      - conda activate dl
      - python dl/prepare_data.py
    artifacts:
      - path: data

  - name: conda-train
    help: Train an model
    deps:
      - workflow: conda-setup
      - workflow: conda-download
    provider: bash
    commands:
      - conda activate dl
      - python dl/train.py
    artifacts:
      - path: lightning_logs

  - name: conda-tune
    help: Run hyperparameter tuning using Optuna and Hydra
    provider: bash
    deps:
      - workflow: conda-setup
      - workflow: conda-download
    commands:
      - conda activate dl
      - python dl/train.py hydra/sweeper=optuna +optuna=tune --multirun
    artifacts:
      - path: lightning_logs
      - path: multirun
